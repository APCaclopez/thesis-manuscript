[#conclusion]
== Conclusion

Sign languages are not well-known in the Philippines, and this study aims to address the issue by developing and evaluating a model that can be used in learning applications. This model aims to assess the execution of a sign and provide feedback regarding mistakes and takes into account facial features, which have been proven to be important for recognizing Filipino Sign Language (FSL). The developed model proved to be decent, achieving an accuracy of 67.50% and precision of 81.82%. To assess the effects of the inclusion of the facial features module, the facial features module was removed and assess as well. This model achieved an accuracy of 70.42% and precision of 75.26%, showing that the inclusion of the facial features module improves precision at the cost of accuracy. Assessing the ability of the model to provide feedback proved difficult due to having a small, imbalanced dataset for this purpose. Due to this, only feedback involving location seemed somewhat reliable, with a precision of 60.00%, a recall of 64.29%, and an F1 score of 62.07%. While these results show that the model is somewhat usable, there is much room to improve.

This study was modeled after the work of Paudyal et al. cite:[paudyal19], however it deviated and achieved different results. Future work may attempt to more closely replicate the model study, as well as try other techniques for the individual modules. In particular, the hand shape and face modules exhibited lower metrics than the other modules and relied on more primitive techniques. They may require the use of more sophisticated methods, such as neural networkâ€“based feature extraction techniques. A more extensive and more balanced dataset is also needed to assess the model's ability to provide feedback.
