[#conclusion]
== Conclusion and Recommendations

This chapter details the final outcomes of the study. This includes addressing the research questions posed and objectives outlined. It also details possible directions that future studies may take.

=== Conclusion

Sign languages are not well-known in the Philippines, and this study aims to address the issue by developing and evaluating a model that can be used in learning applications. This model aims to assess the execution of a sign and provide feedback regarding mistakes and takes into account facial features, which have been proven to be important for recognizing Filipino Sign Language (FSL). The developed model proved to be decent, achieving an accuracy of 67.50% and precision of 81.82%. To assess the effects of the inclusion of the facial features module, the facial features module was removed and assess as well. This model achieved an accuracy of 70.42% and precision of 75.26%, showing that the inclusion of the facial features module improves precision at the cost of accuracy. Assessing the ability of the model to provide feedback proved difficult due to having a small, imbalanced dataset for this purpose. With this in mind, feedback involving location seemed somewhat reliable, with a precision of 60.00%, a recall of 64.29%, and an F1 score of 62.07%. While these results show that the model is somewhat usable, there is much room to improve.

=== Recommendations

While these results show that the model is somewhat capable, there is much room to improve. Possible future directions include the following:

* *Further fine tune and optimize the thresholds.* This study explores the use of a new model for determining the similarity between two videos of sign language gestures. This model is composed of four modules, where each calculates a similarity measure. Thresholds must be set to define what constitutes a significant difference between two gestures. Due to the nature of chaining these different modules together, it is unclear how to balance the metrics as one experiments with different thresholds. Further exploration on the optimal thresholds may yield better results.
* *Use more sophisticated shape-comparing methods for the hand shape and facial expression modules.* The hand shape and facial expression modules exhibited lower metrics than the location module and relied on simpler techniques. There exist more sophisticated techniques specifically designed to compare shapes, like object keypoint similarity (OKS). It may be beneficial to explore the use of these techniques in the modules related to shape comparison.
* *Use more sophisticated dynamic time warping variations for the movement module.* The movement module was found to be less impactful than the other modules. This may be due to the diminishing effectiveness of the dynamic time warping algorithm for longer series. Though the samples were segmented to combat this, the segmentation algorithm used did not consider the alignment of features (i.e., peaks and valleys) in the series. Future work may attempt to use improved variations on the dynamic time warping algorithm that involve more intelligent segmentation methods. As hand shape and facial expression may change throughout the course of the gesture, it may also be beneficial to allow the movement module to inform the frame sampling method used in the hand shape and facial expression modules to ensure that the frames that are compared are taken from the same point in time.
* *Generate more extensive and detailed datasets.* A common problem found in less explored research areas is the lack of datasets, and Filipino Sign Language (FSL) is no exception. While the dataset used in this study contains 105 gestures, there are only around 20 videos per gesture. This prevents the use of techniques that involve the training of more sophisticated machine learning models. There also exist no datasets that label the differences between different gestures, which can be used to assess the feedback of the model.
* *Apply the model in an application.* Finally, this study only explores the creation of a feedback model. The assessments conducted involve the use of datasets, not real-world use. The implementation and integration of the model within a usable application may be explored in future works.
