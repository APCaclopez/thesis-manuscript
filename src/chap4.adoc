[#rnd]
== Results and Discussion

This chapter details the data gathered from following the procedures outlined in <<methodology>>. It also discusses insights regarding this data.

[#results]
=== Results

A model was successfully created as described in <<methodology>>: <<model>> and assessed as described in <<methodology>>: <<assessment>>. Testing was conducted on a subset of 16 gestures from the FSL-105 dataset cite:[tupal23], in which incorrect pairings were undersampled to prevent a class imbalance. Testing was conducted on a total of 480 samples (latexmath:[16\text{ gestures} \cdot \left(15\text{ correct} + 15\text{ incorrect}\right)]).

:table-label-modules: {table-label} {counter:table}
.{table-label-modules}. Individual module metrics.
[#table-module-results]
[%header,cols=6*]
|===
s|Module
s|Threshold
s|Accuracy
s|Precision
s|Recall
s|F1 Score

h|Location
>|0.975
>|69.96%
>|66.43%
>|56.89%
>|72.24%

h|Motion
>|0.500
>|60.63%
>|56.95%
>|71.82%
>|68.86%

h|Shape
>|0.920
>|58.75%
>|55.80%
>|71.63%
>|67.11%

h|Face
>|0.995
>|57.50%
>|55.29%
>|68.12%
>|64.83%
|===

<<table-module-results,{table-label-modules}>> shows the metrics obtained by each individual module when used on the testing data. As the modules simply output a measure of similarity, thresholds must be set to classify correct and incorrect attempts. The thresholds used were experimentally determined prior to testing.

:table-label-models: {table-label} {counter:table}
.{table-label-models}. Model metrics with and without face module.
[#table-model-results]
[%header,cols=5*]
|===
s|Model
s|Accuracy
s|Precision
s|Recall
s|F1 Score

h|With face
>|67.50%
>|81.82%
>|33.33%
>|58.06%

h|Without face
>|70.42%
>|75.26%
>|43.20%
>|67.28%
|===

<<table-model-results,{table-label-models}>> shows the metrics achieved by combining the modules. Compared to the individual modules seen in <<table-module-results,{table-label-modules}>>, combining the modules led to more precise predictions at the cost of worse recall. To determine the impact of including a facial features module, a model which excludes this module was also tested. As seen, the inclusion of a face module gained precision at the cost of all other metrics.

[#discussion]
=== Discussion

The thresholds set for the modules were experimentally chosen in an attempt to balance the different metrics. The model works by chaining together modules by only deeming a pairing correct if all modules output that the pairing is correct. Each additional module only identifies more negative samples. Because of this, while it is ideal for each module to achieve high accuracy and precision, it is also important to maintain a high recall to limit the number of false negatives.

As seen in <<table-module-results,{table-label-modules}>>, the individual modules prove to be somewhat capable of classifying whether pairs of videos are of the same gesture or not, achieving decent metrics. Meanwhile, as seen in <<table-model-results,{table-label-models}>>, Combining the modules together achieves greater precision than any individual module, while maintaining decent accuracy, at the cost of decreased recall and F1 score. This shows that combining the modules better limits false positives at the cost of more false negatives.

To determine the effects of the inclusion of the facial features module, a model without the face module was also tested. Compared to individual modules, this model also achieves better precision, while maintaining accuracy and F1 score, at the cost of worse recall. Compared to this, the model which includes the facial features module achieves better precision at the cost of all other metrics. This shows that the addition of the facial features module further limits false positives at the cost of more false negatives.
