@inproceedings{paudyal19,
author = {Paudyal, Prajwal and Lee, Junghyo and Kamzin, Azamat and Soudki, Mohamad and Banerjee, Ayan and Sandeep, Kornepati},
year = {2019},
month = {Feb},
pages = {},
title = {Learn2Sign: Explainable AI for Sign Language Learning},
}
@article{rastgoo21,
title = {Sign Language Recognition: A Deep Survey},
journal = {Expert Systems with Applications},
volume = {164},
pages = {113794},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113794},
url = {https://www.sciencedirect.com/science/article/pii/S095741742030614X},
author = {Razieh Rastgoo and Kourosh Kiani and Sergio Escalera},
keywords = {Sign language recognition, Pose estimation, Deep learning, Computer Vision, Face recognition, Application},
abstract = {Sign language, as a different form of the communication language, is important to large groups of people in society. There are different signs in each sign language with variability in hand shape, motion profile, and position of the hand, face, and body parts contributing to each sign. So, visual sign language recognition is a complex research area in computer vision. Many models have been proposed by different researchers with significant improvement by deep learning approaches in recent years. In this survey, we review the vision-based proposed models of sign language recognition using deep learning approaches from the last five years. While the overall trend of the proposed models indicates a significant improvement in recognition accuracy in sign language recognition, there are some challenges yet that need to be solved. We present a taxonomy to categorize the proposed models for isolated and continuous sign language recognition, discussing applications, datasets, hybrid models, complexity, and future lines of research in the field.},
}
@misc{peace20,
title = {Why is Communication Important?},
author = {{\relax Piece Into Peace}},
howpublished = {\url{https://www.pieceintopeace.com/blogs/post/15/why-is-communication-important-}},
year = {2020},
month = {Jul},
note = {Accessed May 27, 2024},
}
@misc{borlongan23,
title = {There are 186 languages in the Philippines, not just two! | The Manila Times},
author = {Ariane Macalinga Borlongan},
howpublished = {\url{https://www.manilatimes.net/2023/06/11/opinion/columns/there-are-186-languages-in-the-philippines-not-just-two/1895506}},
year = {2023},
month = {Jun},
}
@misc{tinio18,
title = {Republic Act No. 11106 | Official Gazette of the Republic of the Philippines},
author = {Antonio Tinio},
howpublished = {\url{https://www.manilatimes.net/2023/06/11/opinion/columns/there-are-186-languages-in-the-philippines-not-just-two/1895506}},
year = {2018},
month = {Oct},
note = {Accessed May 27, 2024},
}
@inproceedings{cabutaje23,
author = {Allen Cabutaje, Mark and Ang Brondial, Kenneth and Franchesca Obillo, Alyssa and Abisado, Mideth and Lor Huyo-a, Shekinah and Avelino Sampedro, Gabriel},
booktitle = {2023 International Conference on Electronics, Information, and Communication (ICEIC)}, 
title = {Ano Raw: A Deep Learning Based Approach to Transliterating the Filipino Sign Language}, 
year = {2023},
volume = {},
number = {},
pages = {1-6},
keywords = {Training;Deep learning;Image recognition;Gesture recognition;Auditory system;Assistive technologies;Predictive models;Filipino sign language;convolutional neural network;deep learning},
doi = {10.1109/ICEIC57457.2023.10049890},
}
@inbook{montefalcon23,
author = {Montefalcon, Myron Darrel and Padilla, Jay and Rodriguez, Ramon},
year = {2023},
month = {01},
pages = {489-497},
title = {Filipino Sign Language Recognition Using Long Short-Term Memory and Residual Network Architecture},
isbn = {978-981-19-2396-8},
doi = {10.1007/978-981-19-2397-5_45},
}
@article{kothadiya23,
author = {Kothadiya, Deep R. and Bhatt, Chintan M. and Rehman, Amjad and Alamri, Faten S. and Saba, Tanzila},
journal = {IEEE Access}, 
title = {SignExplainer: An Explainable AI-Enabled Framework for Sign Language Recognition With Ensemble Learning}, 
year = {2023},
volume = {11},
number = {},
pages = {47410-47419},
keywords = {Deep learning;Artificial intelligence;Computational modeling;Predictive models;Assistive technologies;Computer vision;Gesture recognition;Deep learning;computer vision;explainable AI;SignExplainer;classification;sign language;technological development},
doi = {10.1109/ACCESS.2023.3274851},
}
@misc{tupal23,
title = {FSL-105: A dataset for recognizing 105 Filipino sign language videos},
author = {Isaiah Jassen Tupal},
howpublished = {\url{https://dx.doi.org/10.17632/48y2y99mb9.2}},
year = {2023},
month = {Jun},
}
@inproceedings{bajernee20,
author="Banerjee, Ayan
and Lamrani, Imane
and Hossain, Sameena
and Paudyal, Prajwal
and Gupta, Sandeep K. S.",
editor="Bittencourt, Ig Ibert
and Cukurova, Mutlu
and Muldner, Kasia
and Luckin, Rose
and Mill{\'a}n, Eva",
title="AI Enabled Tutor for Accessible Training",
booktitle="Artificial Intelligence in Education",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="29--42",
abstract="A significant number of jobs require highly skilled labor which necessitate training on pre-requisite knowledge. Examples include jobs in military, technical field such computer science, large scale fulfillment centers such as Amazon. Moreover, making such jobs accessible to the disabled population requires even more pre-requisite training such as knowledge of sign language. An artificial intelligent (AI) agent can potentially act as a tutor for such pre-requisite training. This will not only reduce resource requirements for such training but also decrease the time taken for making personnel job ready. In this paper, we develop an AI tutor that can teach users gestures that are required on the field as a pre-requisite. The AI tutor uses a model learning technique that learns the gestures performed by experts. It then uses a model comparison technique to compare a learner with the expert gesture and provides feedback for the learner to improve.",
isbn="978-3-030-52237-7"
}
@misc{python,
title = {Welcome to Python.org},
author = {Python},
howpublished = {https://www.python.org},
year = {2024},
note = {Accessed Jun 4, 2024},
}
@misc{numpy,
title = {NumPy},
author = {NumPy},
howpublished = {https://numpy.org},
year = {2024},
note = {Accessed Jun 4, 2024},
}
@misc{mediapipe,
title = {MediaPipe Solutions guide | Google AI Edge | Google for Developers},
author = {Google},
howpublished = {https://ai.google.dev/edge/mediapipe/solutions/guide},
year = {2024},
note = {Accessed Jun 4, 2024},
}
@misc{tavenard21,
author = {Romain Tavenard},
title = {An introduction to Dynamic Time Warping},
year = {2021},
howpublished = {\url{https://rtavenar.github.io/blog/dtw.html}},
}
@inproceedings{montefalcon21,
author = {Montefalcon, Myron Darrel and Padilla, Jay Rhald and Llabanes Rodriguez, Ramon},
title = {Filipino Sign Language Recognition using Deep Learning},
year = {2021},
isbn = {9781450390156},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485768.3485783},
doi = {10.1145/3485768.3485783},
abstract = {The Filipino deaf community continues to lag behind the fast-paced and technology-driven society in the Philippines. The use of Filipino Sign Language (FSL) has contributed to the improvement of communication of deaf people, however, the majority of the population in the Philippines do not understand FSL. This project utilized computer vision in obtaining the images and Convolutional Neural Network (CNN) ResNet architecture in building the automated FSL recognition model, with the goal of bridging the communication gap between the deaf community and the hearing majorities. In the experimentation, the dataset used are static images generated from a signer which gestured Filipino number signs which range from (0-9). Based on experimentation, the best-achieved performance is on fine-tuned ResNet-50 model which obtained a validation accuracy as high as 86.7\% when the epoch value equals 15. For future work, real-time FSL recognition will be implemented and more data will be collected to enable recognition of Filipino alphabets, basic phrases, and common greetings.},
booktitle = {2021 5th International Conference on E-Society, E-Education and E-Technology},
pages = {219–225},
numpages = {7},
keywords = {Convolutional Neural Network, Filipino Sign Language, ResNet Architecture, Sign Language Recognition},
location = {Taipei, Taiwan},
series = {ICSET 2021},
}
@misc{ivan20,
author = {Grishchenko, Ivan and Bazarevsky, Valentin},
title = {MediaPipe Holistic — Simultaneous Face, Hand and Pose Prediction, on Device | Google Research},
year = {2020},
howpublished = {\url{https://research.google/blog/mediapipe-holistic-simultaneous-face-hand-and-pose-prediction-on-device}},
note = {Accessed Jun 4, 2024},
}
@misc{mediapipePose,
author = {Google Research},
title = {Pose landmark detection guide | Google AI Edge | Google for Developers},
year = {2024},
howpublished = {\url{https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker}},
note = {Accessed June 4, 2024},
}
@misc{mediapipeHand,
author = {Google Research},
title = {Hand landmarks detection guide | Google AI Edge | Google for Developers},
year = {2024},
howpublished = {\url{https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker}},
note = {Accessed June 4, 2024},
}
